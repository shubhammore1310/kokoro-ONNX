{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üé§ OpenWakeWord Model Trainer\n",
        "\n",
        "Train custom wake word models for [openWakeWord](https://github.com/dscripka/openWakeWord).\n",
        "\n",
        "## Features\n",
        "- ‚úÖ Train **multiple wake words** at once\n",
        "- ‚úÖ **Better parameter controls** with clear explanations\n",
        "- ‚úÖ **Quick test mode** for fast iteration\n",
        "- ‚úÖ **Progress logging** with clear status indicators\n",
        "- ‚úÖ **Google Drive integration** for reliable model saving\n",
        "- ‚úÖ Produces **ONNX models** (works with Home Assistant, Python, etc.)\n",
        "\n",
        "## How to Use\n",
        "\n",
        "**Note:** All steps must be executed in order!\n",
        "\n",
        "1. **Step 1**: Test pronunciation - make sure your wake word sounds right\n",
        "2. **Step 2**: Configure training parameters\n",
        "3. **Step 3**: Download data (~15-20 min)\n",
        "4. **Step 4**: Train model (~30-90 min depending on settings) - includes Google Drive option!\n",
        "5. **Step 5**: Download your `.onnx` model file (backup if not using Google Drive)\n",
        "\n",
        "**Tip:** Use GPU runtime for faster training: Runtime ‚Üí Change runtime type ‚Üí T4 GPU"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## üéß Step 1: Test Wake Word Pronunciation { display-mode: \"form\" }\n",
        "# @markdown **Test how your wake word will sound before training!**\n",
        "# @markdown\n",
        "# @markdown First run takes ~1-2 minutes to setup. Subsequent runs are fast.\n",
        "# @markdown\n",
        "# @markdown ### Pronunciation Tips\n",
        "# @markdown - Use underscores for syllable breaks: `computer` ‚Üí `khum_puter`\n",
        "# @markdown - Spell phonetically: `jarvis` ‚Üí `jar_viss`\n",
        "# @markdown - Multi-word: `hey jarvis` ‚Üí `hey_jar_viss`\n",
        "# @markdown - Spell out numbers: `2` ‚Üí `two`\n",
        "# @markdown - Avoid punctuation except `?` and `!`\n",
        "\n",
        "target_word = 'hey_jar_viss' # @param {type:\"string\"}\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "# Setup TTS on first run\n",
        "if not os.path.exists(\"./piper-sample-generator\"):\n",
        "    print(\"üîß First run - setting up TTS engine (~1-2 minutes)...\")\n",
        "    !git clone https://github.com/rhasspy/piper-sample-generator\n",
        "    !wget -q -O piper-sample-generator/models/en_US-libritts_r-medium.pt 'https://github.com/rhasspy/piper-sample-generator/releases/download/v2.0.0/en_US-libritts_r-medium.pt'\n",
        "    !cd piper-sample-generator && git checkout 213d4d5\n",
        "    !pip install -q piper-tts piper-phonemize-cross\n",
        "    !pip install -q webrtcvad\n",
        "    !pip install -q --force-reinstall 'torch==2.4.0' 'torchaudio==2.4.0' torchvision\n",
        "    print(\"‚úÖ TTS setup complete!\\n\")\n",
        "\n",
        "if \"piper-sample-generator/\" not in sys.path:\n",
        "    sys.path.append(\"piper-sample-generator/\")\n",
        "\n",
        "# Check for torch/torchaudio compatibility\n",
        "try:\n",
        "    import torchaudio\n",
        "    torchaudio.load  # Test that it works\n",
        "except (OSError, ImportError) as e:\n",
        "    if \"undefined symbol\" in str(e) or \"libtorchaudio\" in str(e):\n",
        "        print(\"‚ö†Ô∏è Torch/torchaudio version mismatch detected!\")\n",
        "        print(\"   This happens if Step 3 was run before Step 1.\")\n",
        "        print(\"   Please: Runtime ‚Üí Restart session, then run Step 1 first.\")\n",
        "        raise RuntimeError(\"Please restart runtime and run Step 1 before Step 3\")\n",
        "\n",
        "# ============================================================\n",
        "# FIX: Patch torch.load ONLY ONCE to avoid recursion error\n",
        "# ============================================================\n",
        "import torch\n",
        "\n",
        "# Check if we've already patched torch.load (prevents RecursionError on re-run)\n",
        "if not getattr(torch.load, '_oww_patched', False):\n",
        "    _original_torch_load = torch.load\n",
        "\n",
        "    def _patched_torch_load(*args, **kwargs):\n",
        "        kwargs.setdefault('weights_only', False)\n",
        "        return _original_torch_load(*args, **kwargs)\n",
        "\n",
        "    # Mark it as patched so we don't do it again\n",
        "    _patched_torch_load._oww_patched = True\n",
        "    torch.load = _patched_torch_load\n",
        "\n",
        "from generate_samples import generate_samples\n",
        "\n",
        "def preview_wake_word(text):\n",
        "    \"\"\"Generate and play a sample of the wake word.\"\"\"\n",
        "    print(f\"üé§ Generating audio for: '{text}'\")\n",
        "    generate_samples(\n",
        "        text=text,\n",
        "        max_samples=1,\n",
        "        length_scales=[1.1],\n",
        "        noise_scales=[0.7],\n",
        "        noise_scale_ws=[0.7],\n",
        "        output_dir='./',\n",
        "        batch_size=1,\n",
        "        auto_reduce_batch_size=True,\n",
        "        file_names=[\"test_generation.wav\"]\n",
        "    )\n",
        "    return Audio(\"test_generation.wav\", autoplay=True)\n",
        "\n",
        "print(\"\\n‚ñ∂Ô∏è Listen to your wake word:\")\n",
        "display(preview_wake_word(target_word))\n",
        "print(\"\\nüí° If it doesn't sound right, change the spelling above and run again!\")\n",
        "print(\"   Once satisfied, proceed to Step 2.\")"
      ],
      "metadata": {
        "id": "step1_preview"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## ‚öôÔ∏è Step 2: Training Configuration { display-mode: \"form\" }\n",
        "# @markdown ### Wake Words\n",
        "# @markdown Enter one or more wake words, separated by commas.\n",
        "# @markdown Use the exact spelling that sounded best in Step 1!\n",
        "# @markdown\n",
        "# @markdown **Examples:** `hey_jar_viss` or `hey_jar_viss, oh_kay_computer`\n",
        "\n",
        "wake_words = \"hey_jar_viss\" # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown ### Quick Test Mode\n",
        "# @markdown Enable for faster training (~30 min) with lower quality. Good for testing!\n",
        "quick_test_mode = False # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown ### Training Parameters\n",
        "# @markdown These are ignored if Quick Test Mode is enabled.\n",
        "# @markdown\n",
        "# @markdown | Parameter | Low | Default | High | Effect |\n",
        "# @markdown |-----------|-----|---------|------|--------|\n",
        "# @markdown | Examples | 5,000 | 25,000 | 50,000 | More = better quality, longer training |\n",
        "# @markdown | Steps | 5,000 | 25,000 | 50,000 | More = better convergence, longer training |\n",
        "# @markdown | False Activation Penalty | 500 | 1,500 | 3,000 | Higher = fewer false triggers, may miss quiet speech |\n",
        "\n",
        "_number_of_examples = 25000 # @param {type:\"slider\", min:1000, max:50000, step:1000}\n",
        "_number_of_training_steps = 25000 # @param {type:\"slider\", min:1000, max:50000, step:1000}\n",
        "_false_activation_penalty = 1500 # @param {type:\"slider\", min:100, max:5000, step:100}\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown ### Advanced Options\n",
        "# @markdown\n",
        "# @markdown **target_false_positives_per_hour** - How often model incorrectly triggers\n",
        "# @markdown - `0.1` = ~1 false trigger every 10 hours (very strict)\n",
        "# @markdown - `0.5` = ~1 false trigger every 2 hours (stricter)\n",
        "# @markdown - `1.0` = ~1 false trigger per hour (permissive)\n",
        "\n",
        "target_false_positives_per_hour = 0.7 # @param {type:\"number\"}\n",
        "\n",
        "# @markdown **target_recall** - Percentage of real wake words detected (at evaluation threshold)\n",
        "# @markdown - `0.5` = 50% detected (conservative, fewer false positives)\n",
        "# @markdown - `0.7` = 70% detected (balanced)\n",
        "# @markdown - `0.9` = 90% detected (sensitive, more false positives)\n",
        "\n",
        "target_recall = 0.7 # @param {type:\"number\"}\n",
        "\n",
        "# @markdown **layer_size** - Neural network hidden layer size (affects model size and accuracy)\n",
        "# @markdown - `32` = ~15 KB model, fastest inference, good for simple single words\n",
        "# @markdown - `64` = ~30 KB model, fast, balanced\n",
        "# @markdown - `96` = ~50 KB model, better accuracy for multi-word phrases\n",
        "# @markdown - `128` = ~75 KB model, best accuracy, slower inference\n",
        "\n",
        "layer_size = 96 # @param [32, 64, 96, 128] {type:\"raw\"}\n",
        "\n",
        "# Hidden defaults (not exposed in UI)\n",
        "target_accuracy = 0.7  # Not configurable - doesn't significantly affect training\n",
        "\n",
        "# ============================================================\n",
        "# APPLY SETTINGS\n",
        "# ============================================================\n",
        "\n",
        "# Parse wake words\n",
        "wake_word_list = [w.strip() for w in wake_words.split(',') if w.strip()]\n",
        "\n",
        "if not wake_word_list:\n",
        "    raise ValueError(\"‚ùå No wake words specified! Enter at least one wake word above.\")\n",
        "\n",
        "# Apply quick test mode\n",
        "if quick_test_mode:\n",
        "    number_of_examples = 5000\n",
        "    number_of_training_steps = 5000\n",
        "    false_activation_penalty = 500\n",
        "    print(\"‚ö° QUICK TEST MODE ENABLED\")\n",
        "    print(\"   Using reduced settings for faster training (~30 min)\")\n",
        "    print(\"   Model quality will be lower - for testing only!\")\n",
        "else:\n",
        "    number_of_examples = _number_of_examples\n",
        "    number_of_training_steps = _number_of_training_steps\n",
        "    false_activation_penalty = _false_activation_penalty\n",
        "\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(f\"üìã TRAINING CONFIGURATION\")\n",
        "print(f\"{'='*50}\")\n",
        "print(f\"\\nüéØ Wake words to train: {wake_word_list}\")\n",
        "print(f\"\\nüìä Training parameters:\")\n",
        "print(f\"   ‚Ä¢ Examples per word: {number_of_examples:,}\")\n",
        "print(f\"   ‚Ä¢ Training steps: {number_of_training_steps:,}\")\n",
        "print(f\"   ‚Ä¢ False activation penalty: {false_activation_penalty}\")\n",
        "print(f\"\\nüìà Evaluation targets:\")\n",
        "print(f\"   ‚Ä¢ Target FP/hour: {target_false_positives_per_hour}\")\n",
        "print(f\"   ‚Ä¢ Target recall: {target_recall*100:.0f}%\")\n",
        "print(f\"\\nüß† Model architecture:\")\n",
        "print(f\"   ‚Ä¢ Layer size: {layer_size} neurons\")\n",
        "print(f\"\\n‚úÖ Configuration saved. Proceed to Step 3.\")"
      ],
      "metadata": {
        "id": "step2_config"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## üì¶ Step 3: Download Data & Setup Environment { display-mode: \"form\" }\n",
        "# @markdown This downloads all required data and installs dependencies.\n",
        "# @markdown\n",
        "# @markdown **Time:** ~15-20 minutes (mostly downloading)\n",
        "# @markdown\n",
        "# @markdown **What gets downloaded:**\n",
        "# @markdown - Pre-computed audio features (~17 GB) - for negative examples\n",
        "# @markdown - Validation features (~176 MB) - for false positive testing\n",
        "# @markdown - Room impulse responses - for reverb augmentation\n",
        "# @markdown - Background audio (music/noise) - for augmentation\n",
        "# @markdown\n",
        "# @markdown ‚ö†Ô∏è **License Note:** Data has mixed licenses. Models trained here are for **non-commercial personal use only**.\n",
        "\n",
        "import locale\n",
        "def getpreferredencoding(do_setlocale=True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"üì¶ STEP 3: ENVIRONMENT SETUP & DATA DOWNLOAD\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# ============================================================\n",
        "# 3.1 INSTALL DEPENDENCIES (must happen before scipy/numpy imports!)\n",
        "# ============================================================\n",
        "print(\"\\nüîß Installing dependencies...\")\n",
        "\n",
        "# Unload any cached numpy/scipy modules to avoid version conflicts\n",
        "mods_to_remove = [k for k in sys.modules.keys() if k.startswith(('numpy', 'scipy'))]\n",
        "for mod in mods_to_remove:\n",
        "    del sys.modules[mod]\n",
        "\n",
        "# Fix numpy/scipy compatibility FIRST\n",
        "!pip install -q --force-reinstall 'numpy==1.26.4' 'scipy==1.13.1'\n",
        "\n",
        "!git clone -q https://github.com/dscripka/openwakeword 2>/dev/null || echo \"openwakeword already cloned\"\n",
        "!pip install -q -e ./openwakeword --no-deps\n",
        "\n",
        "# Core dependencies\n",
        "!pip install -q mutagen==1.47.0\n",
        "!pip install -q torchinfo==1.8.0\n",
        "!pip install -q torchmetrics==1.2.0\n",
        "!pip install -q speechbrain==0.5.14\n",
        "!pip install -q audiomentations==0.33.0\n",
        "!pip install -q torch-audiomentations==0.11.0\n",
        "!pip install -q acoustics==0.2.6\n",
        "!pip install -q onnxruntime==1.22.1 ai_edge_litert==1.4.0 onnxsim\n",
        "!pip install -q onnx onnx_graphsurgeon sng4onnx\n",
        "!pip install -q onnx_tf tensorflow 2>/dev/null || true  # Prevents train.py crash\n",
        "!pip install -q pronouncing==0.2.0\n",
        "!pip install -q datasets==2.14.6\n",
        "!pip install -q deep-phonemizer==0.0.19\n",
        "\n",
        "print(\"‚úÖ Dependencies installed\")\n",
        "\n",
        "# ============================================================\n",
        "# NOW import scipy/numpy after installation (fresh import)\n",
        "# ============================================================\n",
        "import numpy as np\n",
        "import scipy.io.wavfile\n",
        "from tqdm.auto import tqdm\n",
        "import datasets\n",
        "\n",
        "print(f\"   numpy version: {np.__version__}\")\n",
        "print(f\"   scipy version: {scipy.__version__}\")\n",
        "\n",
        "# ============================================================\n",
        "# 3.2 DOWNLOAD REQUIRED MODELS\n",
        "# ============================================================\n",
        "print(\"\\nüì• Downloading openWakeWord model files...\")\n",
        "\n",
        "model_dir = \"./openwakeword/openwakeword/resources/models\"\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "model_files = [\n",
        "    (\"embedding_model.onnx\", \"https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/embedding_model.onnx\"),\n",
        "    (\"embedding_model.tflite\", \"https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/embedding_model.tflite\"),\n",
        "    (\"melspectrogram.onnx\", \"https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/melspectrogram.onnx\"),\n",
        "    (\"melspectrogram.tflite\", \"https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/melspectrogram.tflite\"),\n",
        "]\n",
        "\n",
        "for filename, url in model_files:\n",
        "    filepath = os.path.join(model_dir, filename)\n",
        "    if not os.path.exists(filepath):\n",
        "        !wget -q -O {filepath} {url}\n",
        "        print(f\"   ‚úÖ {filename}\")\n",
        "    else:\n",
        "        print(f\"   ‚è≠Ô∏è {filename} (already exists)\")\n",
        "\n",
        "# ============================================================\n",
        "# 3.3 DOWNLOAD ROOM IMPULSE RESPONSES\n",
        "# ============================================================\n",
        "print(\"\\nüì• Downloading room impulse responses...\")\n",
        "\n",
        "rir_dir = \"./mit_rirs\"\n",
        "if not os.path.exists(rir_dir) or len(os.listdir(rir_dir)) < 100:\n",
        "    os.makedirs(rir_dir, exist_ok=True)\n",
        "\n",
        "    # Install git-lfs\n",
        "    !git lfs install\n",
        "\n",
        "    if not os.path.exists(\"MIT_environmental_impulse_responses\"):\n",
        "        !git clone -q https://huggingface.co/datasets/davidscripka/MIT_environmental_impulse_responses\n",
        "\n",
        "    # Process the RIR files\n",
        "    wav_files = list(Path(\"./MIT_environmental_impulse_responses/16khz\").glob(\"*.wav\"))\n",
        "    if wav_files:\n",
        "        rir_dataset = datasets.Dataset.from_dict({\n",
        "            \"audio\": [str(i) for i in wav_files]\n",
        "        }).cast_column(\"audio\", datasets.Audio())\n",
        "\n",
        "        for row in tqdm(rir_dataset, desc=\"Processing RIRs\"):\n",
        "            name = row['audio']['path'].split('/')[-1]\n",
        "            scipy.io.wavfile.write(\n",
        "                os.path.join(rir_dir, name),\n",
        "                16000,\n",
        "                (row['audio']['array'] * 32767).astype(np.int16)\n",
        "            )\n",
        "        print(f\"   ‚úÖ {len(os.listdir(rir_dir))} RIR files\")\n",
        "    else:\n",
        "        print(\"   ‚ö†Ô∏è No RIR files found in cloned repo\")\n",
        "else:\n",
        "    print(f\"   ‚è≠Ô∏è RIRs already downloaded ({len(os.listdir(rir_dir))} files)\")\n",
        "\n",
        "# ============================================================\n",
        "# 3.4 DOWNLOAD BACKGROUND AUDIO\n",
        "# ============================================================\n",
        "print(\"\\nüì• Downloading background audio...\")\n",
        "\n",
        "# AudioSet - currently unavailable due to dataset restructuring\n",
        "audioset_dir = \"./audioset_16k\"\n",
        "\n",
        "if not os.path.exists(audioset_dir) or len([f for f in os.listdir(audioset_dir) if f.endswith('.wav')]) < 50:\n",
        "    os.makedirs(audioset_dir, exist_ok=True)\n",
        "\n",
        "    print(\"   ‚è≠Ô∏è Skipping AudioSet (dataset recently restructured)\")\n",
        "    print(\"   Using FMA + pre-computed features for background audio instead.\")\n",
        "else:\n",
        "    count = len([f for f in os.listdir(audioset_dir) if f.endswith('.wav')])\n",
        "    print(f\"   ‚è≠Ô∏è AudioSet already downloaded ({count} files)\")\n",
        "\n",
        "# FMA (Free Music Archive)\n",
        "fma_dir = \"./fma\"\n",
        "if not os.path.exists(fma_dir) or len([f for f in os.listdir(fma_dir) if f.endswith('.wav')]) < 50:\n",
        "    os.makedirs(fma_dir, exist_ok=True)\n",
        "    print(\"   Loading FMA dataset (streaming)...\")\n",
        "\n",
        "    try:\n",
        "        fma_dataset = datasets.load_dataset(\"rudraml/fma\", name=\"small\", split=\"train\", streaming=True)\n",
        "        fma_dataset = iter(fma_dataset.cast_column(\"audio\", datasets.Audio(sampling_rate=16000)))\n",
        "\n",
        "        n_hours = 3  # 3 hours of music clips for better variety\n",
        "        n_clips = n_hours * 3600 // 30  # FMA clips are 30 seconds each\n",
        "\n",
        "        for i in tqdm(range(n_clips), desc=\"Processing FMA\"):\n",
        "            try:\n",
        "                row = next(fma_dataset)\n",
        "                name = row['audio']['path'].split('/')[-1].replace(\".mp3\", \".wav\")\n",
        "                scipy.io.wavfile.write(\n",
        "                    os.path.join(fma_dir, name),\n",
        "                    16000,\n",
        "                    (row['audio']['array'] * 32767).astype(np.int16)\n",
        "                )\n",
        "            except StopIteration:\n",
        "                break\n",
        "            except Exception as e:\n",
        "                continue  # Skip problematic files\n",
        "        print(f\"   ‚úÖ {len([f for f in os.listdir(fma_dir) if f.endswith('.wav')])} FMA files\")\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ö†Ô∏è FMA download failed: {e}\")\n",
        "else:\n",
        "    count = len([f for f in os.listdir(fma_dir) if f.endswith('.wav')])\n",
        "    print(f\"   ‚è≠Ô∏è FMA already downloaded ({count} files)\")\n",
        "\n",
        "# ============================================================\n",
        "# 3.5 DOWNLOAD PRE-COMPUTED FEATURES\n",
        "# ============================================================\n",
        "print(\"\\nüì• Downloading pre-computed features (this is the big download)...\")\n",
        "\n",
        "# Training features (~17GB)\n",
        "features_file = \"./openwakeword_features_ACAV100M_2000_hrs_16bit.npy\"\n",
        "if not os.path.exists(features_file):\n",
        "    print(\"   ‚¨áÔ∏è Downloading training features (~17 GB)...\")\n",
        "    print(\"   This may take 10-30 minutes depending on connection speed.\")\n",
        "    !wget -q --show-progress https://huggingface.co/datasets/davidscripka/openwakeword_features/resolve/main/openwakeword_features_ACAV100M_2000_hrs_16bit.npy\n",
        "    print(\"   ‚úÖ Training features downloaded\")\n",
        "else:\n",
        "    size_gb = os.path.getsize(features_file) / 1024 / 1024 / 1024\n",
        "    print(f\"   ‚è≠Ô∏è Training features already downloaded ({size_gb:.1f} GB)\")\n",
        "\n",
        "# Validation features (~176MB)\n",
        "val_file = \"validation_set_features.npy\"\n",
        "if not os.path.exists(val_file):\n",
        "    print(\"   ‚¨áÔ∏è Downloading validation features (~176 MB)...\")\n",
        "    !wget -q --show-progress https://huggingface.co/datasets/davidscripka/openwakeword_features/resolve/main/validation_set_features.npy\n",
        "    print(\"   ‚úÖ Validation features downloaded\")\n",
        "else:\n",
        "    size_mb = os.path.getsize(val_file) / 1024 / 1024\n",
        "    print(f\"   ‚è≠Ô∏è Validation features already downloaded ({size_mb:.0f} MB)\")\n",
        "\n",
        "# ============================================================\n",
        "# VERIFICATION\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìä VERIFICATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "def count_wav_files(directory):\n",
        "    if os.path.isdir(directory):\n",
        "        return len([f for f in os.listdir(directory) if f.endswith('.wav')])\n",
        "    return 0\n",
        "\n",
        "rir_count = count_wav_files(rir_dir)\n",
        "audioset_count = count_wav_files(audioset_dir)\n",
        "fma_count = count_wav_files(fma_dir)\n",
        "total_bg = audioset_count + fma_count\n",
        "\n",
        "checks = [\n",
        "    (\"RIRs\", rir_count, 100),\n",
        "    (\"AudioSet\", audioset_count, 0),  # Optional - 0 minimum\n",
        "    (\"FMA\", fma_count, 50),\n",
        "]\n",
        "\n",
        "all_ok = True\n",
        "for name, actual_count, min_count in checks:\n",
        "    if min_count > 0:\n",
        "        status = \"‚úÖ\" if actual_count >= min_count else \"‚ö†Ô∏è\"\n",
        "        print(f\"   {status} {name}: {actual_count} files (need {min_count}+)\")\n",
        "        if actual_count < min_count:\n",
        "            all_ok = False\n",
        "    else:\n",
        "        status = \"‚úÖ\" if actual_count > 0 else \"‚è≠Ô∏è\"\n",
        "        print(f\"   {status} {name}: {actual_count} files (optional)\")\n",
        "\n",
        "# Check feature files\n",
        "for name, path in [(\"Training features\", features_file), (\"Validation features\", val_file)]:\n",
        "    if os.path.exists(path):\n",
        "        size = os.path.getsize(path)\n",
        "        size_str = f\"{size/1024/1024/1024:.1f} GB\" if size > 1024*1024*1024 else f\"{size/1024/1024:.0f} MB\"\n",
        "        print(f\"   ‚úÖ {name} ({size_str})\")\n",
        "    else:\n",
        "        print(f\"   ‚ùå {name} (missing)\")\n",
        "        all_ok = False\n",
        "\n",
        "print(f\"\\n   Total background audio: {total_bg} files (need 50+)\")\n",
        "\n",
        "if total_bg < 50:\n",
        "    all_ok = False\n",
        "\n",
        "if all_ok:\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"‚úÖ STEP 3 COMPLETE - All data downloaded!\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"\\nüëâ Proceed to Step 4 to train your model.\")\n",
        "else:\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"‚ö†Ô∏è Some downloads may have failed.\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"\\nMinimum requirements:\")\n",
        "    print(\"   ‚Ä¢ 50+ total background audio files (AudioSet + FMA)\")\n",
        "    print(\"   ‚Ä¢ Training features file (17 GB)\")\n",
        "    print(\"   ‚Ä¢ Validation features file (176 MB)\")\n",
        "    print(\"\\nRe-run this cell to retry, or proceed if you have enough background audio.\")\n"
      ],
      "metadata": {
        "id": "step3_download"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## üöÄ Step 4: Train Models { display-mode: \"form\" }\n",
        "# @markdown This trains a model for each wake word you specified.\n",
        "# @markdown\n",
        "# @markdown **Time:** ~30-90 minutes per model (depends on settings and hardware)\n",
        "# @markdown\n",
        "# @markdown **Training phases:**\n",
        "# @markdown 1. Generate synthetic speech clips\n",
        "# @markdown 2. Augment clips with noise/reverb\n",
        "# @markdown 3. Train neural network\n",
        "# @markdown 4. Export to ONNX format\n",
        "# @markdown\n",
        "# @markdown ---\n",
        "# @markdown ### üìÅ Google Drive Settings (Recommended!)\n",
        "# @markdown Colab's browser download can be unreliable. Google Drive ensures your models are saved safely.\n",
        "\n",
        "enable_google_drive = True # @param {type:\"boolean\"}\n",
        "# @markdown ‚Üë Enable to save models directly to Google Drive as soon as they finish.\n",
        "\n",
        "drive_folder_name = \"OpenWakeWord_Models\" # @param {type:\"string\"}\n",
        "# @markdown ‚Üë Folder name in your Google Drive (created automatically if it doesn't exist).\n",
        "\n",
        "import yaml\n",
        "import sys\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"üöÄ STEP 4: MODEL TRAINING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# ============================================================\n",
        "# GOOGLE DRIVE SETUP (if enabled)\n",
        "# ============================================================\n",
        "gdrive_enabled = False\n",
        "gdrive_path = None\n",
        "\n",
        "if enable_google_drive:\n",
        "    print(\"\\n‚òÅÔ∏è  Setting up Google Drive...\")\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "\n",
        "        # Check if already mounted\n",
        "        if not os.path.ismount('/content/drive'):\n",
        "            print(\"   (You may be prompted to authorize access)\\n\")\n",
        "            drive.mount('/content/drive')\n",
        "        else:\n",
        "            print(\"   Drive already mounted.\")\n",
        "\n",
        "        # Create the output folder\n",
        "        drive_base = '/content/drive/MyDrive'\n",
        "        drive_output_path = os.path.join(drive_base, drive_folder_name)\n",
        "\n",
        "        if not os.path.exists(drive_output_path):\n",
        "            os.makedirs(drive_output_path)\n",
        "            print(f\"   üìÇ Created folder: Google Drive/{drive_folder_name}/\")\n",
        "        else:\n",
        "            print(f\"   üìÇ Using folder: Google Drive/{drive_folder_name}/\")\n",
        "\n",
        "        # Verify write access\n",
        "        test_file = os.path.join(drive_output_path, '.test_write')\n",
        "        with open(test_file, 'w') as f:\n",
        "            f.write('test')\n",
        "        os.remove(test_file)\n",
        "\n",
        "        gdrive_enabled = True\n",
        "        gdrive_path = drive_output_path\n",
        "        print(f\"   ‚úÖ Google Drive connected! Models will be saved there.\")\n",
        "\n",
        "    except ImportError:\n",
        "        print(\"   ‚ö†Ô∏è Google Drive only available in Colab. Using local storage.\")\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ö†Ô∏è Drive setup failed: {e}\")\n",
        "        print(\"   Models will be downloaded via browser instead.\")\n",
        "else:\n",
        "    print(\"\\nüíæ Google Drive: DISABLED\")\n",
        "    print(\"   Models will be downloaded via browser after training.\")\n",
        "    print(\"   ‚ö†Ô∏è Note: Browser downloads can be unreliable in Colab.\")\n",
        "\n",
        "def sanitize_name(name):\n",
        "    \"\"\"Convert wake word to valid filename.\"\"\"\n",
        "    return re.sub(r'[^a-zA-Z0-9]+', '_', name).strip('_')\n",
        "\n",
        "def save_to_drive(onnx_path, model_name):\n",
        "    \"\"\"Copy model to Google Drive. Returns True if successful.\"\"\"\n",
        "    if not gdrive_enabled or not gdrive_path:\n",
        "        return False\n",
        "\n",
        "    try:\n",
        "        dest_path = os.path.join(gdrive_path, f\"{model_name}.onnx\")\n",
        "        shutil.copy2(onnx_path, dest_path)\n",
        "\n",
        "        # Verify the copy\n",
        "        if os.path.exists(dest_path):\n",
        "            size_kb = os.path.getsize(dest_path) / 1024\n",
        "            print(f\"\\n‚òÅÔ∏è  SAVED TO GOOGLE DRIVE: {model_name}.onnx ({size_kb:.1f} KB)\")\n",
        "            print(f\"   Location: Google Drive/{drive_folder_name}/{model_name}.onnx\")\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"\\n‚ö†Ô∏è  Drive copy verification failed for {model_name}\")\n",
        "            return False\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ö†Ô∏è  Failed to save to Drive: {e}\")\n",
        "        return False\n",
        "\n",
        "def queue_download(onnx_path, model_name):\n",
        "    \"\"\"Queue a model file for browser download (Colab only). Non-blocking.\"\"\"\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        import threading\n",
        "\n",
        "        def trigger_download():\n",
        "            try:\n",
        "                files.download(onnx_path)\n",
        "            except:\n",
        "                pass  # Ignore errors in background thread\n",
        "\n",
        "        print(f\"\\n‚¨áÔ∏è  Queued {model_name}.onnx for download\")\n",
        "        thread = threading.Thread(target=trigger_download)\n",
        "        thread.daemon = True\n",
        "        thread.start()\n",
        "\n",
        "        import time\n",
        "        time.sleep(1)\n",
        "        return True\n",
        "    except ImportError:\n",
        "        print(f\"\\nüìÅ Not running in Colab - find your model at: {onnx_path}\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ö†Ô∏è  Auto-download skipped: {e}\")\n",
        "        return False\n",
        "\n",
        "# ============================================================\n",
        "# LOAD CONFIG AND START TRAINING\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üéØ STARTING TRAINING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "base_config = yaml.load(\n",
        "    open(\"openwakeword/examples/custom_model.yml\", 'r').read(),\n",
        "    yaml.Loader\n",
        ")\n",
        "\n",
        "output_dir = \"./my_custom_model\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "successful_models = []\n",
        "failed_models = []\n",
        "models_saved_to_drive = []\n",
        "models_pending_download = []\n",
        "\n",
        "for i, word in enumerate(wake_word_list):\n",
        "    model_name = sanitize_name(word)\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"üéØ TRAINING MODEL {i+1}/{len(wake_word_list)}: '{word}'\")\n",
        "    print(f\"   Model name: {model_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # Create config for this word\n",
        "    config = base_config.copy()\n",
        "    config[\"target_phrase\"] = [word]\n",
        "    config[\"model_name\"] = model_name\n",
        "    config[\"n_samples\"] = number_of_examples\n",
        "    config[\"n_samples_val\"] = max(500, number_of_examples // 10)\n",
        "    config[\"steps\"] = number_of_training_steps\n",
        "    config[\"target_accuracy\"] = target_accuracy\n",
        "    config[\"target_recall\"] = target_recall\n",
        "    config[\"target_false_positives_per_hour\"] = target_false_positives_per_hour\n",
        "    config[\"output_dir\"] = output_dir\n",
        "    config[\"max_negative_weight\"] = false_activation_penalty\n",
        "    config[\"layer_size\"] = layer_size\n",
        "    config[\"background_paths\"] = ['./audioset_16k', './fma']\n",
        "    config[\"false_positive_validation_data_path\"] = \"validation_set_features.npy\"\n",
        "    config[\"feature_data_files\"] = {\"ACAV100M_sample\": \"openwakeword_features_ACAV100M_2000_hrs_16bit.npy\"}\n",
        "\n",
        "    config_file = f'{model_name}_config.yaml'\n",
        "    with open(config_file, 'w') as f:\n",
        "        yaml.dump(config, f)\n",
        "\n",
        "    try:\n",
        "        # Phase 1: Generate clips\n",
        "        print(f\"\\nüìù Phase 1/3: Generating {number_of_examples:,} synthetic speech clips...\")\n",
        "        !{sys.executable} openwakeword/openwakeword/train.py --training_config {config_file} --generate_clips\n",
        "\n",
        "        # Phase 2: Augment clips\n",
        "        print(f\"\\nüîä Phase 2/3: Augmenting clips with noise and reverb...\")\n",
        "        !{sys.executable} openwakeword/openwakeword/train.py --training_config {config_file} --augment_clips\n",
        "\n",
        "        # Phase 3: Train model\n",
        "        print(f\"\\nüß† Phase 3/3: Training neural network ({number_of_training_steps:,} steps)...\")\n",
        "        !{sys.executable} openwakeword/openwakeword/train.py --training_config {config_file} --train_model\n",
        "\n",
        "        # Check if ONNX was created\n",
        "        onnx_path = f\"{output_dir}/{model_name}.onnx\"\n",
        "        if os.path.exists(onnx_path):\n",
        "            size_kb = os.path.getsize(onnx_path) / 1024\n",
        "            print(f\"\\n‚úÖ SUCCESS: {onnx_path} ({size_kb:.1f} KB)\")\n",
        "\n",
        "            model_info = {\n",
        "                'word': word,\n",
        "                'model_name': model_name,\n",
        "                'onnx_path': onnx_path\n",
        "            }\n",
        "            successful_models.append(model_info)\n",
        "\n",
        "            # Try to save to Google Drive first\n",
        "            if gdrive_enabled and save_to_drive(onnx_path, model_name):\n",
        "                models_saved_to_drive.append(model_info)\n",
        "            else:\n",
        "                # Fall back to queuing download (if not using Drive)\n",
        "                models_pending_download.append(model_info)\n",
        "        else:\n",
        "            print(f\"\\n‚ùå ONNX model not found at {onnx_path}\")\n",
        "            failed_models.append({'word': word, 'error': 'ONNX not created'})\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå Training failed: {e}\")\n",
        "        failed_models.append({'word': word, 'error': str(e)})\n",
        "\n",
        "# ============================================================\n",
        "# SUMMARY\n",
        "# ============================================================\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"üìä TRAINING SUMMARY\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"\\n‚úÖ Successful: {len(successful_models)}\")\n",
        "for m in successful_models:\n",
        "    print(f\"   ‚Ä¢ {m['word']} ‚Üí {m['onnx_path']}\")\n",
        "\n",
        "if failed_models:\n",
        "    print(f\"\\n‚ùå Failed: {len(failed_models)}\")\n",
        "    for m in failed_models:\n",
        "        print(f\"   ‚Ä¢ {m['word']}: {m['error']}\")\n",
        "\n",
        "# Report on saving method\n",
        "if models_saved_to_drive:\n",
        "    print(f\"\\n‚òÅÔ∏è  SAVED TO GOOGLE DRIVE: {len(models_saved_to_drive)} model(s)\")\n",
        "    print(f\"   Location: Google Drive/{drive_folder_name}/\")\n",
        "    for m in models_saved_to_drive:\n",
        "        print(f\"   ‚Ä¢ {m['model_name']}.onnx\")\n",
        "    print(f\"\\n‚ú® Your models are safely stored in Google Drive!\")\n",
        "    print(f\"   You can access them anytime, even after this session ends.\")\n",
        "\n",
        "if models_pending_download:\n",
        "    print(f\"\\n‚¨áÔ∏è  PENDING DOWNLOAD: {len(models_pending_download)} model(s)\")\n",
        "    print(f\"   Run Step 5 to download these models.\")\n",
        "\n",
        "if not successful_models:\n",
        "    print(f\"\\n‚ö†Ô∏è No models were trained successfully. Check the errors above.\")"
      ],
      "metadata": {
        "id": "step4_train"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## ‚¨áÔ∏è Step 5: Download Your Models { display-mode: \"form\" }\n",
        "# @markdown Downloads all generated model files via browser.\n",
        "# @markdown\n",
        "# @markdown **Note:** If you enabled Google Drive in Step 4, your models are already saved there!\n",
        "# @markdown This step is mainly for backup or if you disabled Google Drive.\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"‚¨áÔ∏è STEP 5: DOWNLOAD MODELS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Check for variables from Step 4\n",
        "try:\n",
        "    _gdrive_enabled = gdrive_enabled\n",
        "    _gdrive_path = gdrive_path\n",
        "    _drive_folder = drive_folder_name\n",
        "except NameError:\n",
        "    _gdrive_enabled = False\n",
        "    _gdrive_path = None\n",
        "    _drive_folder = \"OpenWakeWord_Models\"\n",
        "\n",
        "try:\n",
        "    models_to_download = successful_models\n",
        "except NameError:\n",
        "    models_to_download = []\n",
        "\n",
        "if not models_to_download:\n",
        "    print(\"\\n‚ö†Ô∏è No models to download. Run Step 4 first.\")\n",
        "else:\n",
        "    # Show Google Drive status\n",
        "    if _gdrive_enabled and _gdrive_path:\n",
        "        print(f\"\\n‚òÅÔ∏è  Google Drive Status: CONNECTED\")\n",
        "        print(f\"   Your models are already saved to:\")\n",
        "        print(f\"   Google Drive/{_drive_folder}/\")\n",
        "        print(f\"\\n   The download below is a backup copy.\")\n",
        "\n",
        "    print(f\"\\nüì¶ Generated Models:\\n\")\n",
        "    print(f\"{'Model':<35} {'Size':<15} {'Drive Status'}\")\n",
        "    print(f\"{'-'*65}\")\n",
        "\n",
        "    download_files = []\n",
        "    output_dir = \"./my_custom_model\"\n",
        "\n",
        "    for m in models_to_download:\n",
        "        model_name = m['model_name']\n",
        "        onnx_path = m.get('onnx_path', f\"{output_dir}/{model_name}.onnx\")\n",
        "\n",
        "        # Check local file\n",
        "        if os.path.exists(onnx_path):\n",
        "            size_kb = os.path.getsize(onnx_path) / 1024\n",
        "\n",
        "            # Check if it's in Drive\n",
        "            drive_status = \"‚Äî\"\n",
        "            if _gdrive_enabled and _gdrive_path:\n",
        "                drive_file = os.path.join(_gdrive_path, f\"{model_name}.onnx\")\n",
        "                if os.path.exists(drive_file):\n",
        "                    drive_status = \"‚úÖ Saved\"\n",
        "                else:\n",
        "                    drive_status = \"‚ùå Missing\"\n",
        "\n",
        "            print(f\"{model_name}.onnx{' '*(30-len(model_name))} {size_kb:.1f} KB{' '*(10-len(f'{size_kb:.1f}'))} {drive_status}\")\n",
        "            download_files.append(onnx_path)\n",
        "        else:\n",
        "            print(f\"{model_name}.onnx{' '*(30-len(model_name))} ‚ùå not found\")\n",
        "\n",
        "    # Offer to save missing files to Drive\n",
        "    if _gdrive_enabled and _gdrive_path:\n",
        "        missing_from_drive = []\n",
        "        for m in models_to_download:\n",
        "            model_name = m['model_name']\n",
        "            onnx_path = m.get('onnx_path', f\"{output_dir}/{model_name}.onnx\")\n",
        "            drive_file = os.path.join(_gdrive_path, f\"{model_name}.onnx\")\n",
        "            if os.path.exists(onnx_path) and not os.path.exists(drive_file):\n",
        "                missing_from_drive.append((onnx_path, model_name))\n",
        "\n",
        "        if missing_from_drive:\n",
        "            print(f\"\\nüì§ Copying {len(missing_from_drive)} missing model(s) to Google Drive...\")\n",
        "            for onnx_path, model_name in missing_from_drive:\n",
        "                try:\n",
        "                    dest_path = os.path.join(_gdrive_path, f\"{model_name}.onnx\")\n",
        "                    shutil.copy2(onnx_path, dest_path)\n",
        "                    print(f\"   ‚úÖ {model_name}.onnx\")\n",
        "                except Exception as e:\n",
        "                    print(f\"   ‚ùå {model_name}.onnx - {e}\")\n",
        "\n",
        "    # Create zip archive and trigger download\n",
        "    if download_files:\n",
        "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "        zip_name = f'openwakeword_models_{timestamp}'\n",
        "\n",
        "        # Copy files to temp directory for zipping\n",
        "        os.makedirs(zip_name, exist_ok=True)\n",
        "        for f in download_files:\n",
        "            shutil.copy(f, zip_name)\n",
        "\n",
        "        shutil.make_archive(zip_name, 'zip', zip_name)\n",
        "        zip_path = f'{zip_name}.zip'\n",
        "\n",
        "        print(f\"\\nüìÅ Created archive: {zip_path}\")\n",
        "        print(f\"   Size: {os.path.getsize(zip_path) / 1024:.1f} KB\")\n",
        "\n",
        "        # Auto-download in Colab\n",
        "        try:\n",
        "            from google.colab import files\n",
        "            print(\"\\n‚¨áÔ∏è Starting download...\")\n",
        "            print(\"   (If download doesn't start, check your browser's download folder)\")\n",
        "\n",
        "            # Download zip first\n",
        "            files.download(zip_path)\n",
        "\n",
        "            # Also offer individual files\n",
        "            print(\"\\nüì• Individual file downloads:\")\n",
        "            for f in download_files:\n",
        "                try:\n",
        "                    files.download(f)\n",
        "                    print(f\"   ‚úÖ {os.path.basename(f)}\")\n",
        "                except:\n",
        "                    print(f\"   ‚ö†Ô∏è {os.path.basename(f)} - download may have failed\")\n",
        "\n",
        "        except ImportError:\n",
        "            print(f\"\\nüì• Download manually from the file browser on the left.\")\n",
        "\n",
        "        # Cleanup temp dir\n",
        "        shutil.rmtree(zip_name, ignore_errors=True)\n",
        "\n",
        "        if _gdrive_enabled:\n",
        "            print(f\"\\nüí° Remember: Your models are also in Google Drive!\")\n",
        "            print(f\"   Google Drive/{_drive_folder}/\")\n",
        "    else:\n",
        "        print(\"\\n‚ö†Ô∏è No model files found to download.\")"
      ],
      "metadata": {
        "id": "step5_download"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## üß™ Step 6 (Optional): Test Your Models { display-mode: \"form\" }\n",
        "# @markdown Quick sanity check that your models load and run.\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"üß™ STEP 6: MODEL TESTING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "try:\n",
        "    models_to_test = successful_models\n",
        "except NameError:\n",
        "    models_to_test = []\n",
        "\n",
        "output_dir = \"./my_custom_model\"\n",
        "\n",
        "if not models_to_test:\n",
        "    print(\"\\n‚ö†Ô∏è No models to test. Run Step 4 first.\")\n",
        "else:\n",
        "    try:\n",
        "        import openwakeword\n",
        "        from openwakeword.model import Model\n",
        "\n",
        "        for m in models_to_test:\n",
        "            model_name = m['model_name']\n",
        "            word = m['word']\n",
        "            onnx_path = m.get('onnx_path', f\"{output_dir}/{model_name}.onnx\")\n",
        "\n",
        "            print(f\"\\nüìä Testing: {word} ({model_name})\")\n",
        "\n",
        "            if os.path.exists(onnx_path):\n",
        "                try:\n",
        "                    model = Model(\n",
        "                        wakeword_models=[onnx_path],\n",
        "                        inference_framework='onnx'\n",
        "                    )\n",
        "\n",
        "                    # Test with silence (should not trigger)\n",
        "                    test_audio = np.zeros(16000, dtype=np.int16)\n",
        "                    prediction = model.predict(test_audio)\n",
        "\n",
        "                    print(f\"   ‚úÖ Model loaded successfully\")\n",
        "                    print(f\"   Prediction on silence: {prediction}\")\n",
        "                    print(f\"   (Should be close to 0.0 - no wake word in silence)\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"   ‚ùå Error testing model: {e}\")\n",
        "            else:\n",
        "                print(f\"   ‚ö†Ô∏è Model file not found: {onnx_path}\")\n",
        "\n",
        "    except ImportError as e:\n",
        "        print(f\"\\n‚ö†Ô∏è Could not import openwakeword: {e}\")\n",
        "        print(\"   Models were still created - you can test them in your own environment.\")"
      ],
      "metadata": {
        "id": "step6_test"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## üìñ How to Use Your Models\n",
        "\n",
        "### Home Assistant\n",
        "\n",
        "1. Download your `.onnx` model file (from Google Drive or Step 5)\n",
        "2. Copy to your Home Assistant config: `/config/openwakeword/`\n",
        "3. In the openWakeWord add-on settings, add your custom model path\n",
        "4. Restart the add-on\n",
        "\n",
        "See: [Home Assistant openWakeWord docs](https://github.com/home-assistant/addons/blob/master/openwakeword/DOCS.md#custom-wake-word-models)\n",
        "\n",
        "### Python\n",
        "\n",
        "```python\n",
        "from openwakeword.model import Model\n",
        "import pyaudio\n",
        "import numpy as np\n",
        "\n",
        "# Load your model\n",
        "model = Model(wakeword_models=['path/to/your_model.onnx'])\n",
        "\n",
        "# Setup audio stream\n",
        "pa = pyaudio.PyAudio()\n",
        "stream = pa.open(\n",
        "    rate=16000,\n",
        "    channels=1,\n",
        "    format=pyaudio.paInt16,\n",
        "    input=True,\n",
        "    frames_per_buffer=1280\n",
        ")\n",
        "\n",
        "# Listen for wake word\n",
        "print(\"Listening for wake word...\")\n",
        "while True:\n",
        "    audio = np.frombuffer(stream.read(1280), dtype=np.int16)\n",
        "    prediction = model.predict(audio)\n",
        "    \n",
        "    for model_name, score in prediction.items():\n",
        "        if score > 0.5:  # Adjust threshold as needed\n",
        "            print(f\"Wake word detected! Score: {score:.3f}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üîß Troubleshooting\n",
        "\n",
        "### Model doesn't detect well\n",
        "- Try different phonetic spellings in Step 1\n",
        "- Increase `number_of_examples` to 40,000+\n",
        "- Increase `number_of_training_steps` to 40,000+\n",
        "- Lower the detection threshold (e.g., 0.3 instead of 0.5)\n",
        "\n",
        "### Too many false activations\n",
        "- Increase `false_activation_penalty` (try 2000-3000)\n",
        "- Lower `target_false_positives_per_hour` (try 0.1)\n",
        "- Raise the detection threshold (e.g., 0.7 instead of 0.5)\n",
        "\n",
        "### Training times out\n",
        "- Reduce `number_of_examples` to 10,000-20,000\n",
        "- Reduce `number_of_training_steps` to 10,000-20,000\n",
        "- Use Google Colab Pro for longer runtimes\n",
        "- Use GPU runtime (faster training)\n",
        "\n",
        "### Download hangs or fails\n",
        "- **Enable Google Drive in Step 4!** This provides reliable model saving\n",
        "- Models are copied to Drive immediately after each one completes\n",
        "- Even if Colab disconnects, your models are safe in Drive\n",
        "- Re-run Step 5 to retry browser downloads if needed\n",
        "\n",
        "### \"ModuleNotFoundError\" during training\n",
        "- This is usually harmless - check if the `.onnx` file was still created\n",
        "- The training script may show errors about optional components\n",
        "\n",
        "### \"RecursionError\" in Step 1\n",
        "- This was a bug in the torch.load patching - now fixed!\n",
        "- If you still see it, restart the runtime and try again\n",
        "\n",
        "---\n",
        "\n",
        "## üìö Resources\n",
        "\n",
        "- [openWakeWord GitHub](https://github.com/dscripka/openWakeWord)\n",
        "- [openWakeWord Documentation](https://github.com/dscripka/openWakeWord/blob/main/docs/)\n",
        "- [Home Assistant Voice](https://www.home-assistant.io/voice_control/)\n",
        "- [Piper TTS](https://github.com/rhasspy/piper) (used for synthetic speech)"
      ],
      "metadata": {
        "id": "usage_docs"
      }
    }
  ]
}